{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPINE PROBLEMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verify pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import gc\n",
    "import importlib\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import subprocess\n",
    "from typing import Any, Callable\n",
    "import pydicom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 GLOBAL SEATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKDIR_PATH = \"\" # \"../\"\n",
    "IMAGE_DIM = 244\n",
    "NO_CACHE = True\n",
    "CACHE_DIR = WORKDIR_PATH + \".cache/\"\n",
    "DATASET_DIR = WORKDIR_PATH + \"dataset/\"\n",
    "ANOTTATIONS_DIR = DATASET_DIR + \"annotations/\"\n",
    "TRAIN_DIR = DATASET_DIR + \"train_images/\"\n",
    "\n",
    "LOAD_SESSION = False\n",
    "RESOURCES = \"resources/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Functions to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import image_resizer\n",
    "from utils import image_grayscaler\n",
    "from utils import image_normalization\n",
    "from utils import load_image\n",
    "\n",
    "def preprocess(path:str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess a DICOM image through a series of transformations.\n",
    "    \n",
    "    Args:\n",
    "        path (str): File path to the input DICOM image\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed image after resizing, grayscale conversion, and normalization\n",
    "        Returns None if any step in the preprocessing fails\n",
    "    \"\"\"\n",
    "    image = load_image.load_dicom_image(path)\n",
    "    if image is not np.ndarray:\n",
    "        return None\n",
    "    image = image_resizer.resize_image(image, IMAGE_DIM)\n",
    "    image = image_grayscaler.grayscaler(image)\n",
    "    image = image_normalization.normalize_image(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>lesion_type</th><th>image</th></tr><tr><td>str</td><td>list[list[f32]]</td></tr></thead><tbody><tr><td>&quot;Osteophytes&quot;</td><td>[[0.038441, 0.038441, … 0.267448], [0.038441, 0.038441, … 0.221101], … [0.034351, 0.034351, … 0.727099]]</td></tr><tr><td>&quot;Disc space narrowing&quot;</td><td>[[0.09234, 0.09234, … 0.09234], [0.09234, 0.09234, … 0.09234], … [0.09234, 0.09234, … 0.09234]]</td></tr><tr><td>&quot;No finding&quot;</td><td>[[0.007252, 0.007252, … 0.007252], [0.007252, 0.007252, … 0.007252], … [0.007252, 0.007252, … 0.007252]]</td></tr><tr><td>&quot;Osteophytes&quot;</td><td>[[0.09234, 0.09234, … 0.09234], [0.09234, 0.09234, … 0.09234], … [0.09234, 0.09234, … 0.09234]]</td></tr><tr><td>&quot;Vertebral collapse&quot;</td><td>[[0.122338, 0.134899, … 0.293282], [0.132441, 0.14036, … 0.271163], … [0.027581, 0.027034, … 0.669306]]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌──────────────────────┬─────────────────────────────────┐\n",
       "│ lesion_type          ┆ image                           │\n",
       "│ ---                  ┆ ---                             │\n",
       "│ str                  ┆ list[list[f32]]                 │\n",
       "╞══════════════════════╪═════════════════════════════════╡\n",
       "│ Osteophytes          ┆ [[0.038441, 0.038441, … 0.2674… │\n",
       "│ Disc space narrowing ┆ [[0.09234, 0.09234, … 0.09234]… │\n",
       "│ No finding           ┆ [[0.007252, 0.007252, … 0.0072… │\n",
       "│ Osteophytes          ┆ [[0.09234, 0.09234, … 0.09234]… │\n",
       "│ Vertebral collapse   ┆ [[0.122338, 0.134899, … 0.2932… │\n",
       "└──────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import visualice\n",
    "\n",
    "lazy_dataset = any\n",
    "if os.path.exists(CACHE_DIR + \"preprocesed_dataset.parquet\"):\n",
    "    lazy_dataset = pl.read_parquet(CACHE_DIR + 'preprocesed_dataset.parquet').lazy()\n",
    "    NO_CACHE = False\n",
    "else:\n",
    "    lazy_dataset = pl.scan_csv(ANOTTATIONS_DIR + 'p.csv')\n",
    "visualice.visualice_lazyframe(lazy_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Filter dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import visualice\n",
    "\n",
    "if NO_CACHE:\n",
    "    lazy_dataset = (\n",
    "        lazy_dataset\n",
    "        .select(['image_id', 'lesion_type'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Get image path and add to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NO_CACHE:\n",
    "    lazy_dataset = (\n",
    "        lazy_dataset\n",
    "        .with_columns((pl.lit(TRAIN_DIR) + pl.col(\"image_id\")+pl.lit('.dicom')).alias(\"image_path\"))\n",
    "        .drop('image_id')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NO_CACHE:\n",
    "    lazy_dataset = (\n",
    "        lazy_dataset\n",
    "        .with_columns(\n",
    "            pl.col(\"image_path\")\n",
    "            .map_elements(\n",
    "                function=preprocess,\n",
    "                return_dtype=pl.List(pl.List(pl.Float32))\n",
    "                )\n",
    "            .alias(\"image\")\n",
    "        )\n",
    "        .drop(\"image_path\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Save the preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NO_CACHE:\n",
    "    os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "    cache_filename = os.path.join(CACHE_DIR, f\"preprocesed_dataset.parquet\")\n",
    "    lazy_dataset.collect().write_parquet(\n",
    "            cache_filename,\n",
    "            compression=\"snappy\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU(x)=max(0,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOENCODER\n",
    "\n",
    "<img src=\"resources/Structure-of-autoencoder-for-feature-extraction.png\" alt=\"Autoencoder PHoto\" width=\"600px\" height=\"300px\"/>\n",
    "\n",
    "We use an autoencoder for dimensionality reduction, in order to "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
